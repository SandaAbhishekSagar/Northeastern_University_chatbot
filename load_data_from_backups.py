#!/usr/bin/env python3
"""
Load data from ChromaDB backups into the fresh database
"""

import os
import sys
import sqlite3
import json
from pathlib import Path
from typing import List, Dict, Any

# Add services to path
sys.path.append('services/shared')

try:
    import chromadb
    from chromadb.config import Settings
    from sentence_transformers import SentenceTransformer
    print("‚úÖ Required modules imported")
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    sys.exit(1)

def find_backup_data():
    """Find the best backup with data"""
    backup_candidates = [
        "chroma_backups/chroma_backup_20250809_112404",
        "chroma_data_backup_manual",
        "chroma_data_backup_before_efficient_restore_1754159955",
        "chroma_data_backup_before_rebuild_1754159415",
        "chroma_data_backup_before_restore_1754159866"
    ]
    
    for backup_path in backup_candidates:
        if os.path.exists(backup_path):
            chroma_file = os.path.join(backup_path, "chroma.sqlite3")
            if os.path.exists(chroma_file):
                print(f"üìÅ Found backup: {backup_path}")
                return chroma_file
    
    return None

def extract_documents_from_backup(backup_file: str) -> List[Dict[str, Any]]:
    """Extract documents from backup SQLite file"""
    print(f"üìñ Extracting documents from: {backup_file}")
    
    documents = []
    
    try:
        conn = sqlite3.connect(backup_file)
        cursor = conn.cursor()
        
        # Get all tables
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = cursor.fetchall()
        
        print(f"üìä Found {len(tables)} tables")
        
        for (table_name,) in tables:
            if 'collection' in table_name.lower():
                print(f"üîç Processing table: {table_name}")
                
                try:
                    # Get documents from this table
                    cursor.execute(f"""
                        SELECT id, embedding, metadata, document 
                        FROM {table_name}
                        WHERE document IS NOT NULL AND document != ''
                    """)
                    
                    rows = cursor.fetchall()
                    print(f"üìÑ Found {len(rows)} documents in {table_name}")
                    
                    for row in rows:
                        doc_id, embedding, metadata_json, content = row
                        
                        if not content or len(content.strip()) < 10:
                            continue
                        
                        # Parse metadata
                        try:
                            metadata = json.loads(metadata_json) if metadata_json else {}
                        except:
                            metadata = {}
                        
                        # Extract URL and title
                        url = metadata.get('source_url', '') or metadata.get('url', '')
                        title = metadata.get('title', '') or metadata.get('file_name', '')
                        
                        # Filter for Northeastern University content
                        content_lower = content.lower()
                        title_lower = title.lower()
                        url_lower = url.lower()
                        
                        if any(term in content_lower or term in title_lower or term in url_lower for term in [
                            'northeastern', 'neu', 'northeastern.edu'
                        ]):
                            doc = {
                                'id': doc_id,
                                'content': content,
                                'metadata': {
                                    'title': title,
                                    'url': url,
                                    'source_url': url,
                                    'collection': table_name,
                                    'original_metadata': metadata
                                }
                            }
                            documents.append(doc)
                
                except Exception as e:
                    print(f"‚ö†Ô∏è  Error processing table {table_name}: {e}")
                    continue
        
        conn.close()
        print(f"‚úÖ Extracted {len(documents)} Northeastern University documents")
        return documents
        
    except Exception as e:
        print(f"‚ùå Error extracting documents: {e}")
        return []

def load_documents_to_chromadb(documents: List[Dict[str, Any]]):
    """Load documents into ChromaDB"""
    if not documents:
        print("‚ùå No documents to load")
        return False
    
    print(f"üìö Loading {len(documents)} documents to ChromaDB...")
    
    try:
        # Connect to ChromaDB
        client = chromadb.PersistentClient(
            path="chroma_data",
            settings=Settings(anonymized_telemetry=False)
        )
        
        # Get or create documents collection
        try:
            collection = client.get_collection(name="documents")
        except:
            collection = client.create_collection(name="documents")
        
        # Load embedding model
        print("üîÑ Loading embedding model...")
        embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # Prepare data for ChromaDB
        ids = []
        documents_text = []
        metadatas = []
        embeddings = []
        
        for i, doc in enumerate(documents):
            if i % 100 == 0:
                print(f"üìù Processing document {i+1}/{len(documents)}")
            
            ids.append(doc['id'])
            documents_text.append(doc['content'])
            metadatas.append(doc['metadata'])
            
            # Generate embedding
            embedding = embedding_model.encode([doc['content']])[0].tolist()
            embeddings.append(embedding)
        
        # Add to ChromaDB
        print("üíæ Adding documents to ChromaDB...")
        collection.add(
            ids=ids,
            documents=documents_text,
            metadatas=metadatas,
            embeddings=embeddings
        )
        
        print(f"‚úÖ Successfully loaded {len(documents)} documents to ChromaDB")
        return True
        
    except Exception as e:
        print(f"‚ùå Error loading documents: {e}")
        return False

def test_loaded_data():
    """Test that the data was loaded correctly"""
    print("üß™ Testing loaded data...")
    
    try:
        client = chromadb.PersistentClient(
            path="chroma_data",
            settings=Settings(anonymized_telemetry=False)
        )
        
        collection = client.get_collection(name="documents")
        
        # Test query
        results = collection.query(
            query_texts=["Northeastern University admissions"],
            n_results=5
        )
        
        if results['ids'] and results['ids'][0]:
            print(f"‚úÖ Found {len(results['ids'][0])} results for test query")
            
            # Show first result
            if results['metadatas'] and results['metadatas'][0]:
                first_metadata = results['metadatas'][0][0]
                print(f"üìÑ First result: {first_metadata.get('title', 'No title')}")
                print(f"üîó URL: {first_metadata.get('url', 'No URL')}")
            
            return True
        else:
            print("‚ùå No results found for test query")
            return False
            
    except Exception as e:
        print(f"‚ùå Error testing data: {e}")
        return False

def main():
    print("üîÑ Loading Data from Backups to Fresh ChromaDB")
    print("=" * 60)
    
    # Find backup
    backup_file = find_backup_data()
    if not backup_file:
        print("‚ùå No backup found with data")
        return
    
    # Extract documents
    documents = extract_documents_from_backup(backup_file)
    if not documents:
        print("‚ùå No documents extracted from backup")
        return
    
    # Load to ChromaDB
    if load_documents_to_chromadb(documents):
        # Test the loaded data
        if test_loaded_data():
            print("\nüéâ Data loading completed successfully!")
            print("‚úÖ ChromaDB now contains Northeastern University documents")
            print("‚úÖ URLs are preserved and accessible")
            print("‚úÖ Ready to use with the fixed chatbot")
        else:
            print("\n‚ö†Ô∏è  Data loaded but test failed")
    else:
        print("\n‚ùå Data loading failed")

if __name__ == "__main__":
    main()
