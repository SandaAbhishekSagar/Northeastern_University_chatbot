# üåê Public Deployment Guide - Northeastern University Chatbot

## üéØ **Deployment Options Overview**

### **Quick Start (Recommended): Railway.app**
- **Cost**: Free tier available
- **Setup Time**: 15-30 minutes
- **Difficulty**: Easy
- **Best For**: Students, small to medium traffic

### **Production Ready: Render.com**
- **Cost**: Free tier available
- **Setup Time**: 20-40 minutes
- **Difficulty**: Easy
- **Best For**: Production applications

### **Enterprise: AWS/DigitalOcean**
- **Cost**: $5-20/month
- **Setup Time**: 1-2 hours
- **Difficulty**: Medium
- **Best For**: High traffic, custom requirements

## üöÄ **Option 1: Railway.app Deployment (Recommended)**

### **Step 1: Prepare Your Application**

1. **Create a `railway.json` file:**
```json
{
  "build": {
    "builder": "NIXPACKS"
  },
  "deploy": {
    "startCommand": "python start_enhanced_gpu_system.py",
    "healthcheckPath": "/health/enhanced",
    "healthcheckTimeout": 300,
    "restartPolicyType": "ON_FAILURE"
  }
}
```

2. **Create a `Procfile` for Railway:**
```
web: python start_enhanced_gpu_system.py
```

3. **Update your API to use environment variables:**
```python
# In enhanced_gpu_api.py
import os

# Use environment variables for port
PORT = int(os.environ.get("PORT", 8001))
HOST = os.environ.get("HOST", "0.0.0.0")

# Update uvicorn.run
uvicorn.run(
    "enhanced_gpu_api:app",
    host=HOST,
    port=PORT,
    reload=False,
    log_level="info"
)
```

### **Step 2: Deploy to Railway**

1. **Sign up at [railway.app](https://railway.app)**
2. **Connect your GitHub repository**
3. **Create a new project**
4. **Deploy your application**

### **Step 3: Configure Environment Variables**

In Railway dashboard, add these environment variables:
```
PYTHON_VERSION=3.9
OLLAMA_HOST=your-ollama-host
CHROMA_DB_PATH=/app/chroma_data
```

## üåê **Option 2: Render.com Deployment**

### **Step 1: Prepare Application**

1. **Create a `render.yaml` file:**
```yaml
services:
  - type: web
    name: northeastern-chatbot
    env: python
    buildCommand: pip install -r requirements.txt
    startCommand: python start_enhanced_gpu_system.py
    envVars:
      - key: PYTHON_VERSION
        value: 3.9
      - key: OLLAMA_HOST
        value: your-ollama-host
```

### **Step 2: Deploy to Render**

1. **Sign up at [render.com](https://render.com)**
2. **Connect your GitHub repository**
3. **Create a new Web Service**
4. **Configure environment variables**

## üîß **Pre-Deployment Checklist**

### **‚úÖ Code Preparation**
- [ ] Update API to use environment variables for ports
- [ ] Remove hardcoded localhost URLs
- [ ] Add proper CORS headers
- [ ] Update frontend to use relative URLs
- [ ] Test with different port configurations

### **‚úÖ Security Considerations**
- [ ] Add rate limiting
- [ ] Implement API key authentication (optional)
- [ ] Add request validation
- [ ] Configure CORS properly
- [ ] Remove debug information

### **‚úÖ Performance Optimization**
- [ ] Optimize model loading
- [ ] Add caching mechanisms
- [ ] Implement connection pooling
- [ ] Add health checks
- [ ] Monitor resource usage

## üìù **Required Code Changes**

### **1. Update API Configuration**
```python
# services/chat_service/enhanced_gpu_api.py
import os

# Use environment variables
PORT = int(os.environ.get("PORT", 8001))
HOST = os.environ.get("HOST", "0.0.0.0")

# Update uvicorn.run
uvicorn.run(
    "enhanced_gpu_api:app",
    host=HOST,
    port=PORT,
    reload=False,
    log_level="info"
)
```

### **2. Update Frontend Configuration**
```javascript
// frontend/script.js
class UniversityChatbot {
    constructor() {
        // Use environment variable or default to localhost
        this.apiBaseUrl = process.env.API_URL || 'http://localhost:8001';
        // ... rest of constructor
    }
}
```

### **3. Add CORS Headers**
```python
# services/chat_service/enhanced_gpu_api.py
from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure properly for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

## üéØ **Post-Deployment Steps**

### **1. Domain Configuration**
- Set up custom domain (optional)
- Configure SSL certificates
- Set up DNS records

### **2. Monitoring Setup**
- Add logging
- Set up health checks
- Monitor performance
- Set up alerts

### **3. Security Hardening**
- Implement rate limiting
- Add authentication if needed
- Regular security updates
- Monitor for abuse

## üí∞ **Cost Estimation**

### **Railway.app**
- **Free Tier**: $0/month (limited usage)
- **Hobby Plan**: $5/month (1GB RAM, shared CPU)
- **Pro Plan**: $20/month (2GB RAM, dedicated CPU)

### **Render.com**
- **Free Tier**: $0/month (cold starts)
- **Starter Plan**: $7/month (512MB RAM)
- **Standard Plan**: $25/month (1GB RAM)

### **DigitalOcean**
- **Basic Droplet**: $4/month (512MB RAM)
- **Standard Droplet**: $6/month (1GB RAM)

## üöÄ **Quick Start Commands**

### **For Railway.app:**
```bash
# Install Railway CLI
npm install -g @railway/cli

# Login to Railway
railway login

# Deploy your app
railway up
```

### **For Render.com:**
```bash
# Connect your GitHub repo
# Deploy through web interface
# No CLI required
```

## üéâ **Success Metrics**

After deployment, you should have:
- ‚úÖ **Public URL**: Your chatbot accessible worldwide
- ‚úÖ **HTTPS**: Secure connections
- ‚úÖ **Auto-scaling**: Handles traffic spikes
- ‚úÖ **Monitoring**: Performance tracking
- ‚úÖ **Backup**: Automatic backups

## üîó **Next Steps**

1. **Choose your deployment platform**
2. **Prepare your code** (follow the checklist)
3. **Deploy** (follow platform-specific guide)
4. **Test** your public URL
5. **Monitor** performance and usage
6. **Optimize** based on real usage

**Your Northeastern University Chatbot will be accessible to students worldwide!** üåç 